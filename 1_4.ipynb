{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "<image src = \"img\\1_4\\1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countries = [country.name for country in pycountry.countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(word):\n",
    "\t\"\"\"converts an adjectival nationality to its corresponding noun form.\"\"\"\n",
    "\n",
    "\t# list of regex things to check\n",
    "\tpatterns = ['ese', 'ian', 'an', 'ean', 'n', 'ic', 'ern']\n",
    "\t#list of suffixes for appending to country names that get damaged when they are split.\n",
    "\tsuffixes = ['a', 'o']\n",
    "\n",
    "\t# for every potential way of forming a nationality adjective, test them.\n",
    "\tfor pattern in patterns:\n",
    "\t\ttup = re.findall(r'^(.*)(' + pattern + ')', word)\n",
    "\n",
    "\t\t#if the regex finds a pattern, set the country to the stem of the word.\n",
    "\n",
    "\t\tif tup:\n",
    "\t\t\tcountry = tup[0][0]\n",
    "\n",
    "\t\t\t# check to see if the country is in the list of countries returned by pycountry. If it is, return it.\n",
    "\t\t\tif country in countries:\n",
    "\t\t\t\treturn country\n",
    "\n",
    "\t\t\t# if the stem is not a country, try adding suffixes to it to see if you can pull out a real country.\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor suffix in suffixes:\n",
    "\t\t\t\t\tnew_country = country + suffix\n",
    "\t\t\t\t\tif new_country in countries:\n",
    "\t\t\t\t\t\treturn new_country\n",
    "\n",
    "def ex1_processing(list):\n",
    "    new_list = [convert(word) for word in list] \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Argentina', 'Australia', 'Canada']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = ['Argentinian', 'Australian', 'Canadian']\n",
    "ex1_processing(Input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "<image src = \"img\\1_4\\2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James works at Microsoft. She lives in Manchester and likes to play the flute.\n",
      "works\n",
      "at\n",
      "She\n",
      "lives\n",
      "in\n",
      "and\n",
      "likes\n",
      "to\n",
      "play\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_non_nouns(text):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract non-noun words\n",
    "    non_nouns = [token.text for token in doc if token.pos_ not in [\"NOUN\", \"PROPN\"] and not token.is_punct]\n",
    "    \n",
    "    return non_nouns\n",
    "\n",
    "# Input text\n",
    "text = \"James works at Microsoft. She lives in Manchester and likes to play the flute.\"\n",
    "\n",
    "# Get non-noun words\n",
    "non_noun_words = extract_non_nouns(text)\n",
    "\n",
    "# Print the result\n",
    "for word in non_noun_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "<image src = \"img\\1_4\\3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'and']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ex3_processing(text, vocab):\n",
    "    text_list = text.split()\n",
    "    vocab_list = vocab.split()\n",
    "    \n",
    "    Not_appear_list = []\n",
    "    \n",
    "    for word in text_list:\n",
    "        if word not in vocab_list:\n",
    "            Not_appear_list.append(word)\n",
    "    \n",
    "    return Not_appear_list\n",
    "\n",
    "text = \"a text and a vocabulary\"\n",
    "vocab = \"a vocabulary\"\n",
    "\n",
    "ex3_processing(text, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quesstion\n",
    "\n",
    "<image src = \"img\\1_4\\4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "3\n",
      "\n",
      "4\n",
      "2\n",
      "\n",
      "2\n",
      "1\n",
      "\n",
      "10\n",
      "4\n",
      "\n",
      "2\n",
      "1\n",
      "\n",
      "5\n",
      "3\n",
      "\n",
      "3\n",
      "2\n",
      "\n",
      "7\n",
      "5\n",
      "\n",
      "4\n",
      "3\n",
      "\n",
      "2\n",
      "1\n",
      "\n",
      "5\n",
      "4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "word_list = 'Write code to initialize an array and process a list of words'\n",
    "\n",
    "vowels = ['a', 'e', 'i', 'o','u']\n",
    "\n",
    "A = 0\n",
    "\n",
    "for w in word_list.split(\" \"):\n",
    "    if len(w) > A:\n",
    "        A = len(w)\n",
    "\n",
    "word_nonvowels = np.array([[set() for _ in range(A+1)] for _ in range(A+1)])\n",
    "\n",
    "for word in word_list.split(\" \"):\n",
    "    len_w = len(word)\n",
    "    mask = []\n",
    "    for char in word:\n",
    "        if char.lower() not in vowels:\n",
    "            mask.append(char)\n",
    "    len_nonv = len(mask)\n",
    "    if len_nonv > 0:\n",
    "        word_nonvowels[len_w][len_nonv].add(word)\n",
    "        print(len_w)\n",
    "        print(len_nonv)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
