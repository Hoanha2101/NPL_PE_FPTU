{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "<image src = \"img\\1_6\\1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match an arithmetic expression using integers, addition, and multiplication, such as 5*6+9, the regular expression can be defined as follows:\n",
    "\n",
    "regex\n",
    "\n",
    "^\\d+(\\s*[\\+\\*]\\s*\\d+)*$\n",
    "\n",
    "Explanation:\n",
    "- ^: Asserts the position at the start of the string.\n",
    "- \\d+: Matches one or more digits (an integer).\n",
    "- (\\s*[\\+\\*]\\s*\\d+)*: Matches zero or more occurrences of:\n",
    "    + \\s*: Matches zero or more whitespace characters.\n",
    "    + [\\+\\*]: Matches either a + or * operator.\n",
    "    + \\s*: Matches zero or more whitespace characters.\n",
    "    + \\d+: Matches one or more digits (an integer).\n",
    "    + $: Asserts the position at the end of the string.\n",
    "This pattern ensures that the string is a sequence of integers separated by + or * operators with optional spaces.\n",
    "\n",
    "2. Regular Expression for a Single Determiner\n",
    "To match a single determiner (a, an, or the), the regular expression can be defined as follows:\n",
    "\n",
    "regex\n",
    "\n",
    "^(a|an|the)$\n",
    "\n",
    "Explanation:\n",
    "+ ^: Asserts the position at the start of the string.\n",
    "+ (a|an|the): Matches any of the strings a, an, or the.\n",
    "+ $: Asserts the position at the end of the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "<image src = \"img\\1_6\\2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is. a sample . sentence.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "input = '  this is. \\n a sample \\t. sentence.  '\n",
    "\n",
    "def normalize_whitespace(s):\n",
    "    # Strip whitespace from the beginning and end of the string\n",
    "    s = s.strip()\n",
    "    # Normalize whitespace within the string to a single space character\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s\n",
    "\n",
    "normalized_s = normalize_whitespace(input)\n",
    "print(normalized_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "<image src = \"img\\1_6\\3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function shorten(, ) to process  , omitting   most frequently occurring words of  . How readable is it?\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def shorten(text, n):\n",
    "    # Tokenize the text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    \n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Identify the n most frequently occurring words\n",
    "    most_common_words = {word for word, _ in word_counts.most_common(n)}\n",
    "    \n",
    "    # Function to remove the n most frequent words from the original text\n",
    "    def should_keep(word):\n",
    "        return word.lower() not in most_common_words\n",
    "    \n",
    "    # Split original text into words while preserving punctuation\n",
    "    words_with_punctuation = re.findall(r'\\b\\w+\\b|\\W+', text)\n",
    "    \n",
    "    # Filter out the most common words and join the remaining words\n",
    "    filtered_text = ''.join(word for word in words_with_punctuation if should_keep(word))\n",
    "    \n",
    "    return filtered_text.strip()\n",
    "\n",
    "# Example usage\n",
    "text = 'Write a function shorten(text, n) to process a text, omitting the n most frequently occurring words of the text. How readable is it?'\n",
    "n = 5\n",
    "shortened_text = shorten(text, n)\n",
    "print(shortened_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "<image src = \"img\\1_6\\4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Walter',\n",
       " 'feeling anxious',\n",
       " 'He',\n",
       " 'diagnosed today',\n",
       " 'He probably',\n",
       " 'best person I know']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "punc = string.punctuation\n",
    "\n",
    "def remove_punc(text):\n",
    "    list_remove = []\n",
    "    for i in range(len(text)):\n",
    "        if text[i] in punc:\n",
    "           list_remove.append(i)\n",
    "    list_remove.sort(reverse=True)\n",
    "    for i in list_remove:\n",
    "        text = text.replace(text[i], \"\")\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "stop_words = [\"is\",\"the\",\"was\"]\n",
    "\n",
    "Input = \"Walter was feeling anxious. He was diagnosed today. He probably is the best person I know.\"\n",
    "sent_tokenizer = sent_tokenize(Input)\n",
    "new = []\n",
    "for sent in sent_tokenizer:\n",
    "    Input_list = sent.split()\n",
    "    \n",
    "    for i in range(len(Input_list)):\n",
    "        if Input_list[i] in stop_words:\n",
    "            Input_list[i] = \"\"\n",
    "    mask = Input_list[0]\n",
    "    for i in range(1,len(Input_list)):\n",
    "        if Input_list[i] != \"\":\n",
    "            mask = mask + \" \" + Input_list[i]\n",
    "            if i == len(Input_list) - 1:\n",
    "                new.append(remove_punc(mask))\n",
    "        else:\n",
    "            if len(mask) > 0:\n",
    "                new.append(remove_punc(mask))\n",
    "            mask = \"\"\n",
    "    \n",
    "new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
