{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Question 1: Write a Python program that input a text file and outputs the\n",
    "        number of words, characters, sentences in the file.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# punctuation data\n",
    "PUNC = string.punctuation\n",
    "\n",
    "# Open file - Ná»™i dung trong file sample.txt\n",
    "\"\"\"\n",
    "    This is a sample text file.\n",
    "    It contains several sentences.\n",
    "    We can count words, characters, and sentences.\n",
    "    \n",
    "\"\"\"\n",
    "with open(\"sample.txt\", \"r\") as file:\n",
    "    data = file.read()\n",
    "    \n",
    "    #words processing\n",
    "    token_words = nltk.word_tokenize(data)\n",
    "    token_words_process = [i for i in token_words if i not in PUNC]\n",
    "    num_words = len(token_words_process)\n",
    "    \n",
    "    #character processing\n",
    "    count_char = 0\n",
    "    for i in token_words:\n",
    "        count_char = count_char + len(i)\n",
    "    \n",
    "    #Sentences processing\n",
    "    sentences = nltk.sent_tokenize(data)\n",
    "    num_sentences = len(sentences)\n",
    "\n",
    "    \n",
    "print(\"Number of words: \", num_words)\n",
    "print(\"Number of characters: \", count_char)\n",
    "print(\"Number of sentences: \", num_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Question 2: write a Python program that takes a sentences\n",
    "        as input and outputs a new sentences where the FIRST and LAST words are SWAPPED.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "\n",
    "def sentence_swapped(sentence):\n",
    "    \"\"\"\n",
    "    swap words in a sentence\n",
    "    \n",
    "    Args:\n",
    "        sentence: raw sentence\n",
    "        \n",
    "    Returns:\n",
    "        A sentence with first and last words are swapped.\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    #Swap\n",
    "    first_word = tokens[0]\n",
    "    last_word =  tokens[-1]\n",
    "    \n",
    "    tokens[0] = last_word\n",
    "    tokens[-1] = first_word\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# --------- Main ---------\n",
    "sentence = \"This is a sample sentence\"\n",
    "print(sentence_swapped(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Question 3: Write a Python program that takes a document as \n",
    "        input and outputs a dictionary where the keys are the unique\n",
    "        bigrams (two-word phrases) in the document and the values\n",
    "        are the number of times each bigram appears.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# punctuation data\n",
    "PUNC = string.punctuation\n",
    "\n",
    "def processing(document):\n",
    "    \"\"\"\n",
    "    pre-processing document\n",
    "    \n",
    "    Args:\n",
    "        document: raw document\n",
    "        \n",
    "    Returns:\n",
    "        List of lists of words\n",
    "    \"\"\"\n",
    "    \n",
    "    for punc in PUNC:\n",
    "        if punc in document:\n",
    "            document = document.replace(punc,\"\")\n",
    "\n",
    "    return [nltk.word_tokenize(document)]\n",
    "\n",
    "def count_n_grams(data, n = 1):\n",
    "    \"\"\"\n",
    "    Count all n-grams in the data\n",
    "    \n",
    "    Args:\n",
    "        data: List of lists of words\n",
    "        n: number of words in a sequence (default: n = 1 **uni-grams**)\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary that maps a tuple of n-words to its frequency\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize dictionary of n-grams and their counts\n",
    "    n_grams = {}\n",
    "\n",
    "    for sentence in data:\n",
    "        sentence = tuple(sentence)\n",
    "        for i in range(len(sentence) if n==1 else len(sentence)-n+1):\n",
    "            # Get the n-gram from i to i+n\n",
    "            n_gram = sentence[i:i+n]\n",
    "\n",
    "            if n_gram in n_grams.keys():\n",
    "                # Increment the count for this n-gram\n",
    "                n_grams[n_gram] += 1\n",
    "            else:\n",
    "                # Initialize this n-gram count to 1\n",
    "                n_grams[n_gram] = 1\n",
    "\n",
    "    return n_grams\n",
    "\n",
    "\n",
    "# --------- Main ---------\n",
    "document = \"This is a sample document. This document contains several sentences. We can extract bigrams from it.\"\n",
    "\n",
    "#Use n = 2: bi-grams\n",
    "print(count_n_grams(processing(document),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Question 4: Write a Python program that takes a paragraph\n",
    "        of text as input and outputs the number of times each word\n",
    "        appears in the paragraph.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def Count_Token(paragraph):\n",
    "    \"\"\"\n",
    "    Count token\n",
    "    \n",
    "    Args:\n",
    "        paragraph: raw paragraph\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    #tokenization\n",
    "    tokens = paragraph.split(\" \")\n",
    "    \n",
    "    #Set up key\n",
    "    unique_tokens = np.unique(tokens)\n",
    "\n",
    "    #prepare: empty dictionary\n",
    "    Count_Dict = {}\n",
    "\n",
    "    #Count\n",
    "    for i in unique_tokens:\n",
    "        Count_Dict[i] = 0\n",
    "        for j in tokens:\n",
    "            if i == j:\n",
    "                Count_Dict[i] = Count_Dict[i] + 1\n",
    "    return Count_Dict\n",
    "\n",
    "# --------- Main ---------\n",
    "paragraph = \"the quick brown fox jumps over the lazy dog the quick brown fox jumps over the lazy dog\"   \n",
    "print(Count_Token(paragraph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
